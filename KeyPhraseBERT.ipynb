{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KeyPhraseBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hVyLFm0T8hyH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammrit2312/KeyPhrase_BERT/blob/main/KeyPhraseBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch7NBiOIsMVO"
      },
      "source": [
        "# 1. Selecting candidate phrases\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13OtQ47Tru4o"
      },
      "source": [
        "import spacy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et70KlJT4Bnu"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqYvPmI04F4X"
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnzLzIyI4IGC"
      },
      "source": [
        "pattern1 = [{'POS':'ADJ', 'OP':'*'}, {'IS_PUNCT': True, 'OP':'*'}, {'POS':'NOUN', 'OP':'+'},{'IS_PUNCT': True, 'OP':'*'},{'POS':'ADP'},{'OP':'?'},{'POS':'ADJ'},{'IS_PUNCT': True, 'OP':'*'},{'POS':'NOUN'}]\n",
        "#pat = [({'POS':'ADJ', 'OP':'*'}, {'IS_PUNCT': True, 'OP':'*'}, {'POS':'NOUN', 'OP':'+'},{'IS_PUNCT': True, 'OP':'*'},{'POS':'ADP'})?]\n",
        "pattern2 = [{'POS':'ADJ'},{'IS_PUNCT': True, 'OP':'*'},{'POS':'NOUN'}]\n",
        "pattern3 = [{'ENT_TYPE':'ORG', 'OP':'+'}]\n",
        "pattern4 = [{'ENT_TYPE':'GPE', 'OP':'+'}]\n",
        "\n",
        "\n",
        "matcher.add('Noun', None, pattern1, pattern2, pattern3, pattern4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY1KgT3i4VGT"
      },
      "source": [
        "doc = nlp(u'''Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. The batting side scores runs by striking the ball bowled at the wicket with the bat (and running between the wickets), while the bowling and fielding side tries to prevent this (by preventing the ball from leaving the field, and getting the ball to either wicket) and dismiss each batter (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the stumps and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. The game is adjudicated by two umpires, aided by a third umpire and match referee in international matches. They communicate with two off-field scorers who record the match's statistical information.\n",
        "\n",
        "Forms of cricket range from Twenty20, with each team batting for a single innings of 20 overs, to Test matches played over five days. Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.\n",
        "\n",
        "The earliest reference to cricket is in South East England in the mid-16th century. It spread globally with the expansion of the British Empire, with the first international matches in the second half of the 19th century. The game's governing body is the International Cricket Council (ICC), which has over 100 members, twelve of which are full members who play Test matches. The game's rules, the Laws of Cricket, are maintained by Marylebone Cricket Club (MCC) in London. The sport is followed primarily in the Indian subcontinent, Australasia, the United Kingdom, southern Africa and the West Indies.[1] Women's cricket, which is organised and played separately, has also achieved international standard. The most successful side playing international cricket is Australia, which has won seven One Day International trophies, including five World Cups, more than any other country and has been the top-rated Test side more than any other country.''')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzSykpMy4aQf",
        "outputId": "bd579027-373a-4898-ae90-9bc76d0887d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "found_matches = matcher(doc)\n",
        "phrases = set()\n",
        "for matcher_id, start, end in found_matches:\n",
        "  if((start!=end) and (doc[start:end] not in nlp.Defaults.stop_words)):\n",
        "    phrases.add(str(doc[start:end]))\n",
        "\n",
        "phrases=list(phrases)\n",
        "phrases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the United',\n",
              " 'the',\n",
              " 'the International Cricket Council (',\n",
              " '(',\n",
              " 'basic kit',\n",
              " 'the International',\n",
              " 'international matches in the second half',\n",
              " '19th century',\n",
              " 'Empire',\n",
              " 'Cricket Council',\n",
              " 'Cricket Council (',\n",
              " 'Council (ICC',\n",
              " 'Marylebone Cricket',\n",
              " 'half of the 19th century',\n",
              " 'Council (',\n",
              " 'Club',\n",
              " 'British',\n",
              " 'Indian subcontinent',\n",
              " 'Council',\n",
              " 'London',\n",
              " 'single innings',\n",
              " 'the International Cricket',\n",
              " 'other country',\n",
              " 'United',\n",
              " 'the International Cricket Council',\n",
              " 'United Kingdom',\n",
              " 'full members',\n",
              " 'first international matches in the second half',\n",
              " 'the British Empire',\n",
              " 'British Empire',\n",
              " 'matches in the second half',\n",
              " 'second half',\n",
              " 'Cricket Club',\n",
              " 'Kingdom',\n",
              " 'ICC',\n",
              " 'statistical information',\n",
              " 'International',\n",
              " 'International Cricket Council (',\n",
              " 'second half of the 19th century',\n",
              " 'Australasia',\n",
              " 'the British',\n",
              " 'third umpire',\n",
              " 'International Cricket Council (ICC',\n",
              " 'International Cricket Council',\n",
              " 'international cricket',\n",
              " 'the International Cricket Council (ICC',\n",
              " 'Marylebone',\n",
              " 'Marylebone Cricket Club',\n",
              " 'the United Kingdom',\n",
              " 'International Cricket',\n",
              " 'addition to the basic kit',\n",
              " 'white kit',\n",
              " 'successful side',\n",
              " 'Australia',\n",
              " 'earliest reference',\n",
              " 'international standard',\n",
              " 'Cricket Council (ICC',\n",
              " 'Cricket',\n",
              " 'limited overs',\n",
              " '(ICC',\n",
              " 'solid spheroid',\n",
              " 'international matches',\n",
              " 'referee in international matches',\n",
              " 'protective gear',\n",
              " 'Twenty20']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNCYhnJpvdoT"
      },
      "source": [
        "Put the bert part after this \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahz5DmM7vg58",
        "outputId": "6d1996a2-b6bf-491a-af4d-df4233db9335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKj5GVjS8OtN",
        "outputId": "1f7c89ea-1381-4b46-9e2d-09ef7c1d6bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, \n",
        "                                  )\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVyLFm0T8hyH"
      },
      "source": [
        "# 2.Document embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p3Uy3J_8Pex"
      },
      "source": [
        "document='''Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. The batting side scores runs by striking the ball bowled at the wicket with the bat (and running between the wickets), while the bowling and fielding side tries to prevent this (by preventing the ball from leaving the field, and getting the ball to either wicket) and dismiss each batter (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the stumps and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. The game is adjudicated by two umpires, aided by a third umpire and match referee in international matches. They communicate with two off-field scorers who record the match's statistical information.\n",
        "Forms of cricket range from Twenty20, with each team batting for a single innings of 20 overs, to Test matches played over five days. Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.\n",
        "The earliest reference to cricket is in South East England in the mid-16th century. It spread globally with the expansion of the British Empire, with the first international matches in the second half of the 19th century. The game's governing body is the International Cricket Council (ICC), which has over 100 members, twelve of which are full members who play Test matches. The game's rules, the Laws of Cricket, are maintained by Marylebone Cricket Club (MCC) in London. The sport is followed primarily in the Indian subcontinent, Australasia, the United Kingdom, southern Africa and the West Indies.[1] Women's cricket, which is organised and played separately, has also achieved international standard. The most successful side playing international cricket is Australia, which has won seven One Day International trophies, including five World Cups, more than any other country and has been the top-rated Test side more than any other country.'''\n",
        "sentences= document.split('. ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN3BqwaS8Pms"
      },
      "source": [
        "#here we tokenize each sentence and convert to ids\n",
        "#finding maximum length of a sentence (for padding purposes, because bert requires this)\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sentence in sentences:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    sentence_id = tokenizer.encode(sentence, add_special_tokens=True)\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(sentence_id))\n",
        "#adding 10 extra to max_len just in case\n",
        "max_len=max_len+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OOD1axt8Pt2",
        "outputId": "0f81a427-4bf9-45ce-f6d5-b680fd1f5802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "# input ids is a 2d list, each element is a list(that represents a sentence which is tokenised and converted to the ids)\n",
        "#attention masks is also a 2d list each element is a list(that represents whether each element of the tokenised list is a padded element or not)\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# For every phrase...\n",
        "for sentence in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the phrase.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the phrase to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                      # phrase to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation = True,\n",
        "                        max_length = 23 ,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded phrase to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g2E8nnO8P62",
        "outputId": "c915c3dd-d96d-459d-de7b-4660f857b703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#this is where we call the model and pass the encoded tokens of each sentence\n",
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers.\n",
        "hidden_states=[]\n",
        "with torch.no_grad():\n",
        "    for i in range(len(input_ids)):\n",
        "      outputs = model(input_ids[i],attention_mask=attention_masks[i])\n",
        "      hidden_states.append(outputs[2])\n",
        "\n",
        "print(len(hidden_states[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrKEMqpD8QBl"
      },
      "source": [
        "#here we calculate sentence and document embeddings\n",
        "# `hidden_states` has shape [no of sentences x 13 x 1 x max_len x 768]\n",
        "sentence_embeddings=[]\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "for i in range(len(hidden_states)):\n",
        "  token_vecs = hidden_states[i][-2][0]#we take the embeddings from the second last layer as it has the best balance in terms of context\n",
        "  # Calculate the average of all token vectors.\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "  sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = torch.stack(sentence_embeddings,dim=0)\n",
        "document_embedding=torch.mean(sentence_embeddings, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX5Nu8399OMG"
      },
      "source": [
        "# 3.phrase embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydvStJU08QIs",
        "outputId": "057088e1-5f46-4176-880d-ceae3f6c6945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#finding maximum length of a phrase (for padding purposes, because bert requires this)\n",
        "max_len = 0\n",
        "\n",
        "for phrase in phrases:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    ids = tokenizer.encode(phrase, add_special_tokens=True)\n",
        "    # Update the maximum phrase length.\n",
        "    max_len = max(max_len, len(ids))\n",
        "    \n",
        "#adding 10 extra to max_len just in case\n",
        "max_len=max_len+10\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyQY3tCf9L7h",
        "outputId": "7d0cb398-e6df-44ef-f3ad-77723f640888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the phrases and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# For every phrase...\n",
        "for phrase in phrases:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the phrase.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the phrase to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        phrase,                      # phrase to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation = True,\n",
        "                        max_length = 23 ,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded phrase to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKYt3sk69MOJ"
      },
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers.\n",
        "hidden_states=[]\n",
        "with torch.no_grad():\n",
        "    for i in range(len(input_ids)):\n",
        "      outputs = model(input_ids[i],attention_mask=attention_masks[i])\n",
        "      hidden_states.append(outputs[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St_oVbxJ9MZJ"
      },
      "source": [
        "# `hidden_states` has shape [no of sentences x 13 x 1 x max_len x 768]\n",
        "phrase_embeddings=[]\n",
        "for i in range(len(hidden_states)):\n",
        "  token_vecs = hidden_states[i][-2][0]\n",
        "  # `token_vecs` is a tensor with shape [22 x 768]\n",
        "  # Calculate the average of all token vectors.\n",
        "  phrase_embedding = torch.mean(token_vecs, dim=0)\n",
        "  phrase_embeddings.append(phrase_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weriTWAA9iJi"
      },
      "source": [
        "# 4.cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Fxp7uY9Mhp",
        "outputId": "7297dab3-e787-419d-bf39-e873eb2e5df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "selected_keyphrases=set()\n",
        "\n",
        "for i in range(len(phrase_embeddings)):\n",
        "  diff = 1 - cosine(document_embedding, phrase_embeddings[i])\n",
        "  print(\"keyphrase: \",phrases[i])\n",
        "  print(\"similarity: \",diff*100,\"%\\n\\n\")\n",
        "  if(diff>=0.675):\n",
        "    selected_keyphrases.add(phrases[i])\n",
        "\n",
        "print(selected_keyphrases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keyphrase:  the United\n",
            "similarity:  64.50136303901672 %\n",
            "\n",
            "\n",
            "keyphrase:  the\n",
            "similarity:  59.27771329879761 %\n",
            "\n",
            "\n",
            "keyphrase:  the International Cricket Council (\n",
            "similarity:  70.11339068412781 %\n",
            "\n",
            "\n",
            "keyphrase:  (\n",
            "similarity:  59.67443585395813 %\n",
            "\n",
            "\n",
            "keyphrase:  basic kit\n",
            "similarity:  66.57353639602661 %\n",
            "\n",
            "\n",
            "keyphrase:  the International\n",
            "similarity:  63.796836137771606 %\n",
            "\n",
            "\n",
            "keyphrase:  international matches in the second half\n",
            "similarity:  65.09360671043396 %\n",
            "\n",
            "\n",
            "keyphrase:  19th century\n",
            "similarity:  60.11441349983215 %\n",
            "\n",
            "\n",
            "keyphrase:  Empire\n",
            "similarity:  67.00421571731567 %\n",
            "\n",
            "\n",
            "keyphrase:  Cricket Council\n",
            "similarity:  70.85310816764832 %\n",
            "\n",
            "\n",
            "keyphrase:  Cricket Council (\n",
            "similarity:  65.77544212341309 %\n",
            "\n",
            "\n",
            "keyphrase:  Council (ICC\n",
            "similarity:  55.14177083969116 %\n",
            "\n",
            "\n",
            "keyphrase:  Marylebone Cricket\n",
            "similarity:  70.18466591835022 %\n",
            "\n",
            "\n",
            "keyphrase:  half of the 19th century\n",
            "similarity:  61.14004850387573 %\n",
            "\n",
            "\n",
            "keyphrase:  Council (\n",
            "similarity:  59.6185028553009 %\n",
            "\n",
            "\n",
            "keyphrase:  Club\n",
            "similarity:  64.38702344894409 %\n",
            "\n",
            "\n",
            "keyphrase:  British\n",
            "similarity:  64.05222415924072 %\n",
            "\n",
            "\n",
            "keyphrase:  Indian subcontinent\n",
            "similarity:  69.12643313407898 %\n",
            "\n",
            "\n",
            "keyphrase:  Council\n",
            "similarity:  63.55111002922058 %\n",
            "\n",
            "\n",
            "keyphrase:  London\n",
            "similarity:  62.79914379119873 %\n",
            "\n",
            "\n",
            "keyphrase:  single innings\n",
            "similarity:  66.74687266349792 %\n",
            "\n",
            "\n",
            "keyphrase:  the International Cricket\n",
            "similarity:  70.97066044807434 %\n",
            "\n",
            "\n",
            "keyphrase:  other country\n",
            "similarity:  66.83164834976196 %\n",
            "\n",
            "\n",
            "keyphrase:  United\n",
            "similarity:  64.03805017471313 %\n",
            "\n",
            "\n",
            "keyphrase:  the International Cricket Council\n",
            "similarity:  71.50585055351257 %\n",
            "\n",
            "\n",
            "keyphrase:  United Kingdom\n",
            "similarity:  64.83232975006104 %\n",
            "\n",
            "\n",
            "keyphrase:  full members\n",
            "similarity:  64.74919319152832 %\n",
            "\n",
            "\n",
            "keyphrase:  first international matches in the second half\n",
            "similarity:  68.23749542236328 %\n",
            "\n",
            "\n",
            "keyphrase:  the British Empire\n",
            "similarity:  66.83153510093689 %\n",
            "\n",
            "\n",
            "keyphrase:  British Empire\n",
            "similarity:  67.3956573009491 %\n",
            "\n",
            "\n",
            "keyphrase:  matches in the second half\n",
            "similarity:  60.27600169181824 %\n",
            "\n",
            "\n",
            "keyphrase:  second half\n",
            "similarity:  65.14296531677246 %\n",
            "\n",
            "\n",
            "keyphrase:  Cricket Club\n",
            "similarity:  66.8473482131958 %\n",
            "\n",
            "\n",
            "keyphrase:  Kingdom\n",
            "similarity:  58.063483238220215 %\n",
            "\n",
            "\n",
            "keyphrase:  ICC\n",
            "similarity:  69.65189576148987 %\n",
            "\n",
            "\n",
            "keyphrase:  statistical information\n",
            "similarity:  65.06785154342651 %\n",
            "\n",
            "\n",
            "keyphrase:  International\n",
            "similarity:  66.66054725646973 %\n",
            "\n",
            "\n",
            "keyphrase:  International Cricket Council (\n",
            "similarity:  70.10980248451233 %\n",
            "\n",
            "\n",
            "keyphrase:  second half of the 19th century\n",
            "similarity:  61.849141120910645 %\n",
            "\n",
            "\n",
            "keyphrase:  Australasia\n",
            "similarity:  65.993732213974 %\n",
            "\n",
            "\n",
            "keyphrase:  the British\n",
            "similarity:  63.72366547584534 %\n",
            "\n",
            "\n",
            "keyphrase:  third umpire\n",
            "similarity:  67.25166440010071 %\n",
            "\n",
            "\n",
            "keyphrase:  International Cricket Council (ICC\n",
            "similarity:  67.7206814289093 %\n",
            "\n",
            "\n",
            "keyphrase:  International Cricket Council\n",
            "similarity:  74.97742772102356 %\n",
            "\n",
            "\n",
            "keyphrase:  international cricket\n",
            "similarity:  72.94525504112244 %\n",
            "\n",
            "\n",
            "keyphrase:  the International Cricket Council (ICC\n",
            "similarity:  70.01179456710815 %\n",
            "\n",
            "\n",
            "keyphrase:  Marylebone\n",
            "similarity:  61.7995023727417 %\n",
            "\n",
            "\n",
            "keyphrase:  Marylebone Cricket Club\n",
            "similarity:  70.29317021369934 %\n",
            "\n",
            "\n",
            "keyphrase:  the United Kingdom\n",
            "similarity:  62.618666887283325 %\n",
            "\n",
            "\n",
            "keyphrase:  International Cricket\n",
            "similarity:  72.94525504112244 %\n",
            "\n",
            "\n",
            "keyphrase:  addition to the basic kit\n",
            "similarity:  66.04107618331909 %\n",
            "\n",
            "\n",
            "keyphrase:  white kit\n",
            "similarity:  68.86751055717468 %\n",
            "\n",
            "\n",
            "keyphrase:  successful side\n",
            "similarity:  65.43681025505066 %\n",
            "\n",
            "\n",
            "keyphrase:  Australia\n",
            "similarity:  68.22977066040039 %\n",
            "\n",
            "\n",
            "keyphrase:  earliest reference\n",
            "similarity:  65.1402235031128 %\n",
            "\n",
            "\n",
            "keyphrase:  international standard\n",
            "similarity:  66.36742353439331 %\n",
            "\n",
            "\n",
            "keyphrase:  Cricket Council (ICC\n",
            "similarity:  65.63899517059326 %\n",
            "\n",
            "\n",
            "keyphrase:  Cricket\n",
            "similarity:  70.22819519042969 %\n",
            "\n",
            "\n",
            "keyphrase:  limited overs\n",
            "similarity:  70.41966319084167 %\n",
            "\n",
            "\n",
            "keyphrase:  (ICC\n",
            "similarity:  56.079161167144775 %\n",
            "\n",
            "\n",
            "keyphrase:  solid spheroid\n",
            "similarity:  66.24836325645447 %\n",
            "\n",
            "\n",
            "keyphrase:  international matches\n",
            "similarity:  65.44728875160217 %\n",
            "\n",
            "\n",
            "keyphrase:  referee in international matches\n",
            "similarity:  69.58571672439575 %\n",
            "\n",
            "\n",
            "keyphrase:  protective gear\n",
            "similarity:  65.09715914726257 %\n",
            "\n",
            "\n",
            "keyphrase:  Twenty20\n",
            "similarity:  67.21609830856323 %\n",
            "\n",
            "\n",
            "{'the International Cricket', 'ICC', 'referee in international matches', 'the International Cricket Council (', 'the International Cricket Council', 'International Cricket Council (', 'Cricket', 'Cricket Council', 'limited overs', 'Marylebone Cricket', 'International Cricket Council (ICC', 'International Cricket Council', 'international cricket', 'first international matches in the second half', 'the International Cricket Council (ICC', 'Marylebone Cricket Club', 'Australia', 'International Cricket', 'Indian subcontinent', 'white kit'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SbBUieivhNn",
        "outputId": "3ceb3c4e-0f61-43fc-e8cc-0c57bc746cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "k=1\n",
        "for i in selected_keyphrases:\n",
        "  print(k,\". \",i,\"\\n\")\n",
        "  k+=1\n",
        "print(\"no of candidate phrases: \",len(phrases))\n",
        "print(\"no of selected phrases: \",len(selected_keyphrases))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 .  the International Cricket \n",
            "\n",
            "2 .  ICC \n",
            "\n",
            "3 .  referee in international matches \n",
            "\n",
            "4 .  the International Cricket Council ( \n",
            "\n",
            "5 .  the International Cricket Council \n",
            "\n",
            "6 .  International Cricket Council ( \n",
            "\n",
            "7 .  Cricket \n",
            "\n",
            "8 .  Cricket Council \n",
            "\n",
            "9 .  limited overs \n",
            "\n",
            "10 .  Marylebone Cricket \n",
            "\n",
            "11 .  International Cricket Council (ICC \n",
            "\n",
            "12 .  International Cricket Council \n",
            "\n",
            "13 .  international cricket \n",
            "\n",
            "14 .  first international matches in the second half \n",
            "\n",
            "15 .  the International Cricket Council (ICC \n",
            "\n",
            "16 .  Marylebone Cricket Club \n",
            "\n",
            "17 .  Australia \n",
            "\n",
            "18 .  International Cricket \n",
            "\n",
            "19 .  Indian subcontinent \n",
            "\n",
            "20 .  white kit \n",
            "\n",
            "no of candidate phrases:  65\n",
            "no of selected phrases:  20\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}